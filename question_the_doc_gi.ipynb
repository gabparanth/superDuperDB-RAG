{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c042ddbb-c2c9-46ed-b36c-c965c0d7ff5b",
   "metadata": {},
   "source": [
    "# Ask the docs anything about SuperDuperDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6fbce6-fec9-47af-8701-99721eedec50",
   "metadata": {},
   "source": [
    "In this notebook we show you how to implement the much-loved document Q&A task, using SuperDuperDB\n",
    "together with MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6858da67-597d-4d98-ae4a-41003bb569f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install superduperdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5bcdade-f988-4464-bfcf-806245031bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = ''\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    raise Exception('Environment variable \"OPENAI_API_KEY\" not set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42c42cc-af6a-4712-a993-d9c921693819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Uncomment one of the following lines to use a bespoke MongoDB deployment\n",
    "# For testing the default connection is to mongomock\n",
    "\n",
    "# mongodb_uri = os.getenv(\"MONGODB_URI\", \"mongomock://test\")\n",
    "mongodb_uri = \"mongodb://localhost:27017/testTest\"\n",
    "# mongodb_uri = \"mongodb://superduper:superduper@mongodb:27017/documents\"\n",
    "# mongodb_uri = \"mongodb://<user>:<pass>@<mongo_cluster>/<database>\"\n",
    "# mongodb_uri = \"mongodb+srv://<username>:<password>@<atlas_cluster>/<database>\"\n",
    "\n",
    "# Super-Duper your Database!\n",
    "from superduperdb import superduper\n",
    "db = superduper(mongodb_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d041c9c3-4c48-4550-9d84-ac319daf5d7d",
   "metadata": {},
   "source": [
    "In this example we use the internal textual data from the `superduperdb` project's API documentation, with the \"meta\"-goal of \n",
    "creating a chat-bot to tell us about the project which we are using!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db46140-1758-41ba-8fde-0ed8bd78eac7",
   "metadata": {},
   "source": [
    "Uncomment the following cell if you have the superduperdb project locally, and would like to load the latest version of the API.\n",
    "Otherwise you can load the data in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a2a52-964f-456e-88b6-040965f5ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "\n",
    "# ROOT = '../docs/content/docs'\n",
    "\n",
    "# STRIDE = 5       # stride in numbers of lines\n",
    "# WINDOW = 10       # length of window in numbers of lines\n",
    "\n",
    "# content = sum([open(file).readlines() \n",
    "#                for file in glob.glob(f'{ROOT}/*/*.md') \n",
    "#                + glob.glob('{ROOT}/*.md')], [])\n",
    "# chunks = ['\\n'.join(content[i: i + WINDOW]) for i in range(0, len(content), STRIDE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8074e665-b1e1-4256-9ea8-e8502f264cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  139k  100  139k    0     0   510k      0 --:--:-- --:--:-- --:--:--  511k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://superduperdb-public.s3.eu-west-1.amazonaws.com/superduperdb_docs.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e587e284-0876-4464-a977-ac97a9070787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('superduperdb_docs.json') as f:\n",
    "    chunks = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c4636-88c6-42a4-b471-41be7c20680f",
   "metadata": {},
   "source": [
    "You can see that the chunks of text contain bits of code, and explanations, \n",
    "which can become useful in building a document Q&A chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a3a6ef-6cba-4655-9822-0ea4f9151f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "  ML directly to the datastore: to databases, object-storage, data-lakes and data-warehouses.\n",
       "\n",
       "- Empower developers, data scientists and architects to leverage the vast AI\n",
       "\n",
       "  **open-source ecosystem** in their datastore deployments.\n",
       "\n",
       "- Enable ways-of-working with AI and data which **enable scalability** and industrial scale deployment,\n",
       "\n",
       "  as well as providing easy-to-use tools for the **individual developer**.\n",
       "\n",
       "- Make possible continued use of **already existing or deployed datastores**, in combination with AI and ML;\n",
       "\n",
       "  **no migration of data** to a fancy, new fangled vector-database required.\n",
       "\n",
       "- Follow a **fully open-source approach**, in particular prioritizing open-source integrations\n",
       "\n",
       "  in our roadmap going forward\n",
       "\n",
       "- Enable individuals and organizations to **circumvent vendor lock-in strategies** now ubiquitous\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(chunks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370732b-0c55-4672-b6be-0830f9a3a755",
   "metadata": {},
   "source": [
    "As usual we insert the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7208ef2-c035-43b9-a624-ade42a06ed09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:found 0 uris\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<pymongo.results.InsertManyResult at 0x2a0521270>,\n",
       " TaskWorkflow(database=<superduperdb.db.base.db.DB object at 0x2a0774d50>, G=<networkx.classes.digraph.DiGraph object at 0x2a04c9b90>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from superduperdb.container.document import Document\n",
    "import json\n",
    "from superduperdb.db.mongodb.query import Collection\n",
    "from superduperdb.container.document import Document as D\n",
    "collection = Collection('questiondocs')\n",
    "db.execute(collection.insert_many([Document({'txt': chunk}) for chunk in chunks]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b299b6f-37ae-46d7-b064-7d368d98d68a",
   "metadata": {},
   "source": [
    "We set up a standard `superduperdb` vector-search index using `openai` (although there are many options\n",
    "here: `torch`, `sentence_transformers`, `transformers`, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa132d0-e6a2-46f6-9eb8-13fbce90ff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Adding model text-embedding-ada-002 to db\n",
      "WARNING:root:model/text-embedding-ada-002/0 already exists - doing nothing\n",
      "INFO:root:Done.\n",
      "373it [00:00, 18593.94it/s]\n",
      "100%|██████████| 4/4 [00:06<00:00,  1.66s/it]\n",
      "INFO:root:loading hashes: 'my-index'\n",
      "Loading vectors into vector-table...: 373it [00:00, 1989.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from superduperdb.container.vector_index import VectorIndex\n",
    "from superduperdb.container.listener import Listener\n",
    "from superduperdb.ext.openai.model import OpenAIEmbedding\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        identifier='my-index',\n",
    "        indexing_listener=Listener(\n",
    "            model=OpenAIEmbedding(model='text-embedding-ada-002'),\n",
    "            key='txt',\n",
    "            select=collection.find(),\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c184f40-f11a-41af-b28b-5e39cf7b68ad",
   "metadata": {},
   "source": [
    "Now we create a chat-completion component, and add this to the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abfa4df6-73ac-4d46-8047-011648e24958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from superduperdb.ext.openai.model import OpenAIChatCompletion\n",
    "\n",
    "chat = OpenAIChatCompletion(\n",
    "    model='gpt-3.5-turbo',\n",
    "    prompt=(\n",
    "        'Use the following description and code-snippets aboout SuperDuperDB to answer this question about SuperDuperDB\\n'\n",
    "        'Do not use any other information you might have learned about other python packages\\n'\n",
    "        'Only base your answer on the code-snippets retrieved\\n'\n",
    "        '{context}\\n\\n'\n",
    "        'Here\\'s the question:\\n'\n",
    "    ),\n",
    ")\n",
    "\n",
    "db.add(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb65997-7263-4608-b17b-282c5f90dcfb",
   "metadata": {},
   "source": [
    "We can view that this is now registered in the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4cae6a5-d9d1-49da-b5bf-c12fe6247b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-3.5-turbo', 'text-embedding-ada-002']\n"
     ]
    }
   ],
   "source": [
    "print(db.show('model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ac7bb-eaaf-4bec-9561-603b3c98a736",
   "metadata": {},
   "source": [
    "Finally, asking questions about the documents can be targeted with a particular query.\n",
    "Using the power of MongoDB, this allows users to use vector-search in combination with\n",
    "important filtering rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc4a0f6c-9e24-47aa-bc73-7cc4507e94ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:loading hashes: 'my-index'\n",
      "Loading vectors into vector-table...: 373it [00:00, 1866.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Yes, you can use vector search with MongoDB community. The code snippets and description provided mention that SuperDuperDB includes a composite API that enables support for vector search together with the query API of the database. It also mentions that if one or more `VectorIndex` instances have been configured together with the `DB`, they can be used in hybrid queries together with standard databasing queries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from superduperdb.container.document import Document\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "q = 'can I use vector search with MongoDB community'\n",
    "\n",
    "output, context = db.predict(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    input=q,\n",
    "    context_select=(\n",
    "        collection\n",
    "            .like(Document({'txt': q}), vector_index='my-index', n=5)\n",
    "            .find()\n",
    "    ),\n",
    "    context_key='txt',\n",
    ")\n",
    "\n",
    "Markdown(output.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
